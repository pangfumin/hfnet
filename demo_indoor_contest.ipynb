{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pang/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/pang/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/pang/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/pang/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/pang/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/pang/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import sys,os\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from hfnet.settings import EXPER_PATH\n",
    "from notebooks.utils import plot_images, plot_matches, add_frame\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R, Slerp \n",
    "from numpy.linalg import inv, norm\n",
    "logging.basicConfig(format='[%(asctime)s %(levelname)s] %(message)s',\n",
    "                    datefmt='%m/%d/%Y %H:%M:%S',\n",
    "                    level=logging.INFO)\n",
    "from hfnet.datasets import get_dataset  # noqa: E402\n",
    "from hfnet.evaluation.loaders import export_loader  # noqa: E402\n",
    "from hfnet.settings import EXPER_PATH  # noqa: E402\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10/24/2019 17:52:53 INFO] Restoring parameters from /home/pang/software/hfnet_venv/hfnet_exp/saved_models/hfnet/variables/variables\n"
     ]
    }
   ],
   "source": [
    "tf.contrib.resampler  # import C++ op\n",
    "class HFNet:\n",
    "    def __init__(self, model_path, outputs):\n",
    "        self.session = tf.Session()\n",
    "        self.image_ph = tf.placeholder(tf.float32, shape=(None, None, 3))\n",
    "\n",
    "        net_input = tf.image.rgb_to_grayscale(self.image_ph[None])\n",
    "        tf.saved_model.loader.load(\n",
    "            self.session, [tag_constants.SERVING], str(model_path),\n",
    "            clear_devices=True,\n",
    "            input_map={'image:0': net_input})\n",
    "\n",
    "        graph = tf.get_default_graph()\n",
    "        self.outputs = {n: graph.get_tensor_by_name(n+':0')[0] for n in outputs}\n",
    "        self.nms_radius_op = graph.get_tensor_by_name('pred/simple_nms/radius:0')\n",
    "        self.num_keypoints_op = graph.get_tensor_by_name('pred/top_k_keypoints/k:0')\n",
    "    def inference(self, image, nms_radius=4, num_keypoints=1000):\n",
    "        inputs = {\n",
    "            self.image_ph: image[..., ::-1].astype(np.float),\n",
    "            self.nms_radius_op: nms_radius,\n",
    "            self.num_keypoints_op: num_keypoints,\n",
    "        }\n",
    "        return self.session.run(self.outputs, feed_dict=inputs)\n",
    "\n",
    "model_path = Path(EXPER_PATH, 'saved_models/hfnet')\n",
    "outputs = ['global_descriptor', 'keypoints', 'local_descriptors','scores']\n",
    "hfnet = HFNet(model_path, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance(desc1, desc2):\n",
    "    # For normalized descriptors, computing the distance is a simple matrix multiplication.\n",
    "    return 2 * (1 - desc1 @ desc2.T)\n",
    "\n",
    "def match_with_ratio_test(desc1, desc2, thresh):\n",
    "    dist = compute_distance(desc1, desc2)\n",
    "    nearest = np.argpartition(dist, 2, axis=-1)[:, :2]\n",
    "    dist_nearest = np.take_along_axis(dist, nearest, axis=-1)\n",
    "    valid_mask = dist_nearest[:, 0] <= (thresh**2)*dist_nearest[:, 1]\n",
    "    matches = np.stack([np.where(valid_mask)[0], nearest[valid_mask][:, 0]], 1)\n",
    "    return matches\n",
    "\n",
    "def undistortion(distP,fx,fy,cx,cy,w):\n",
    "    u_p = [0.,0.]\n",
    "    d_p = [0.,0.]\n",
    "#     print(\"dp0:{} dp1:{} fx:{}\".format(d_p[0],d_p[1],fx)\n",
    "    d_p[0] = (float(distP[0]) - cx)/fx\n",
    "    d_p[1] = (float(distP[1]) - cy)/fy\n",
    "#     print(\"dp0:{} dp1:{} fx:{}\".format((float(d_p[0]) - cx)/fx,float(d_p[1]) - cx,fx))\n",
    "    mul2tanwby2 = np.tan(w / 2.0) * 2.0\n",
    "    \n",
    "#     Calculate distance from point to center.\n",
    "    r_d = np.sqrt(d_p[0]*d_p[0] + d_p[1]*d_p[1])\n",
    "    if mul2tanwby2 == 0 or r_d == 0:\n",
    "        print(\"tanw error\")\n",
    "        return u_p\n",
    "    \n",
    "#     Calculate undistorted radius of point.\n",
    "    kMaxValidAngle = 89.0;\n",
    "    if abs(r_d * w) <= kMaxValidAngle:\n",
    "        r_u = np.tan(r_d * w) / (r_d * mul2tanwby2)\n",
    "    else:\n",
    "        print('angle not valid')\n",
    "        return u_p\n",
    "\n",
    "    u_p[0] = d_p[0] * r_u;\n",
    "    u_p[1] = d_p[1] * r_u;\n",
    "\n",
    "    u_p[0] = u_p[0]* fx + cx;\n",
    "    u_p[1] = u_p[1]* fy + cy;\n",
    "    return u_p\n",
    "\n",
    "def kpData2Dic(data):\n",
    "    assert len(data)%3==0\n",
    "    dict={}\n",
    "    for i in range(0,len(data),3):\n",
    "        dict[int(i/3)] = [float(data[i]),float(data[i+1]),int(data[i+2])]\n",
    "    return dict\n",
    "def loadSfmModel(filePath):\n",
    "    p = open(filePath+'/points3D.txt')\n",
    "    tmp3d = [ line.split(' ') for line in p.readlines()[3:]]\n",
    "    points3D={}\n",
    "    for line in tmp3d:\n",
    "        e = [float(e) for e in line]\n",
    "        points3D[e[0]] = e[1:]\n",
    "    i=open(filePath+'/images.txt')\n",
    "    images={}\n",
    "    imagesData = i.readlines()[4:]\n",
    "    for i in range(0,len(imagesData),2):\n",
    "        l1 = imagesData[i].split(' ')\n",
    "        l2 = imagesData[i+1].split(' ')\n",
    "        if len(l1) == 10:\n",
    "            kpDic = kpData2Dic(l2)\n",
    "            name = l1[-1][:-1]\n",
    "            pose = [float(e) for e in l1[1:8]]\n",
    "            images[name]= {'pose':pose,'keypointsDic':kpDic}\n",
    "    return points3D,images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "db_path =  \"/home/pang/colmap_ws/office/office-1-5/sfm1/\"\n",
    "query_path =\"/home/pang/data/dataset/iros2019slam/office/office-1-1/fisheye1/\" \n",
    "\n",
    "db_list = os.listdir(db_path)\n",
    "query_list = os.listdir(query_path)\n",
    "query_list.sort()\n",
    "db_list.sort()\n",
    "\n",
    "db_image = lambda n: cv2.imread(db_path + n)[:, :, ::-1]\n",
    "query_image = lambda n: cv2.imread(query_path + n)[:, :, ::-1]\n",
    "images_db = [db_image(frame) for frame in db_list]\n",
    "images_query = [query_image(frame) for frame in query_list]\n",
    "\n",
    "db = [hfnet.inference(i) for i in images_db]\n",
    "global_index = np.stack([d['global_descriptor'] for d in db])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relocalization happend with:1560000083949067.png total reloc number:1\n",
      "relocalization happend with:1560000084949025.png total reloc number:2\n",
      "relocalization happend with:1560000085948989.png total reloc number:3\n",
      "relocalization happend with:1560000086948943.png total reloc number:4\n",
      "relocalization happend with:1560000087948944.png total reloc number:5\n",
      "relocalization happend with:1560000088948908.png total reloc number:6\n",
      "relocalization happend with:1560000089948820.png total reloc number:7\n",
      "relocalization happend with:1560000090948780.png total reloc number:8\n",
      "relocalization happend with:1560000091948755.png total reloc number:9\n",
      "relocalization happend with:1560000092948720.png total reloc number:10\n",
      "relocalization happend with:1560000093948675.png total reloc number:11\n",
      "relocalization happend with:1560000094948609.png total reloc number:12\n",
      "relocalization happend with:1560000095948579.png total reloc number:13\n",
      "relocalization happend with:1560000096948526.png total reloc number:14\n",
      "relocalization happend with:1560000097948493.png total reloc number:15\n",
      "relocalization happend with:1560000098948442.png total reloc number:16\n",
      "relocalization happend with:1560000099948402.png total reloc number:17\n",
      "relocalization happend with:1560000100948346.png total reloc number:18\n",
      "relocalization happend with:1560000101948317.png total reloc number:19\n",
      "relocalization happend with:1560000102948280.png total reloc number:20\n"
     ]
    }
   ],
   "source": [
    "modelPath = '/home/pang/colmap_ws/practice1/hfnet/sparse/'\n",
    "result_path = \"/home/pang/colmap_ws/result_image1-1/\"\n",
    "w =  open(\"/home/pang/colmap_ws/result1-1/images.txt\",'w')\n",
    "w1 = open(\"/home/pang/colmap_ws/result1-1/reloc1-1.txt\",'w')\n",
    "\n",
    "if not os.path.isdir(result_path):\n",
    "    os.makedirs(result_path)\n",
    "else:\n",
    "    filelist = os.listdir(result_path)\n",
    "    for img in filelist:\n",
    "        os.remove(\"{}/{}\".format(result_path,img))   \n",
    "        \n",
    "plotMatch = False\n",
    "dbPoints3D,dbImages = loadSfmModel(modelPath)\n",
    "# fisheye\n",
    "fx=284.981\n",
    "fy=286.102\n",
    "cx=425.244\n",
    "cy=398.468\n",
    "k1=-7.3047108016908169e-03\n",
    "k2=4.3499931693077087e-02\n",
    "k3=-4.1283041238784790e-02\n",
    "k4=7.6524601317942142e-03\n",
    "\n",
    "#284.981,286.102,425.244,398.468,-7.3047108016908169e-03,4.3499931693077087e-02,-4.1283041238784790e-02,7.6524601317942142e-03\n",
    "\n",
    "count=0\n",
    "K = np.array([[fx,0,cx],[0,fy,cy],[0,0,1]])\n",
    "D = np.array([k1,k2,k3,k4])\n",
    "\n",
    "### knn candidate\n",
    "nn = 20\n",
    "ratio_test = 0.7\n",
    "\n",
    "relocResult=[]\n",
    "locResultStr=[]\n",
    "contestResultStr=[]\n",
    "keypoints2D={}\n",
    "# for i in range(len(images_query)):\n",
    "    \n",
    "for i in range(0,800,30):\n",
    "    globalKpNum = []\n",
    "    query = hfnet.inference(images_query[i])\n",
    "    nearest = np.argsort(compute_distance(query['global_descriptor'], global_index))[:nn]\n",
    "    undistKps=np.array([[0.,0.]],dtype=np.float32)\n",
    "    imps=np.array([[0.,0.,0.]])\n",
    "    allMatches=np.array([[0, 0]])\n",
    "\n",
    "    for item in nearest:\n",
    "        matches = match_with_ratio_test(query['local_descriptors'],\n",
    "                                db[item]['local_descriptors'], ratio_test)\n",
    "        if len(matches) <=3:\n",
    "            continue\n",
    "        distKp = query['keypoints'][matches[:,0]]\n",
    "        distKp = np.array([distKp],dtype=np.float32)\n",
    "      \n",
    "        undistKp = cv2.undistortPoints(distKp,K,D,P=K)\n",
    "        undistKp = undistKp.reshape((-1,2))\n",
    "        \n",
    "        if db_list[item] in dbImages:\n",
    "            impsIdx = [dbImages[db_list[item]]['keypointsDic'][m[1]][2] for m in matches]\n",
    "        else:\n",
    "            continue\n",
    "        impsIdx = np.array(impsIdx)\n",
    "        a = np.where(np.array(impsIdx)>=0)  \n",
    "        if len(a) <1:\n",
    "            continue\n",
    "        undistKp = undistKp[a]\n",
    "        impsIdx=impsIdx[a]\n",
    "        matches = matches[a]\n",
    "\n",
    "        imp = [dbPoints3D[idx][:3] for idx in impsIdx]\n",
    "        imp = np.array(imp)\n",
    "        \n",
    "\n",
    "        if len(imp) <1:\n",
    "            continue;\n",
    "        imps = np.concatenate((imps, imp),axis=0)\n",
    "        undistKps = np.concatenate((undistKps,undistKp),axis = 0)\n",
    "        allMatches = np.concatenate((allMatches,matches), axis = 0)\n",
    "        globalKpNum.append([item,len(imps)-1])\n",
    "    \n",
    "   \n",
    "    imps=imps[1:]\n",
    "    undistKps=undistKps[1:]\n",
    "    allMatches=allMatches[1:]\n",
    "\n",
    "\n",
    "    if len(imps) <=4 :\n",
    "        continue\n",
    "    success, R_vec, t, inliers = cv2.solvePnPRansac(\n",
    "        imps, undistKps, K, np.array([0., 0., 0., 0.]),\n",
    "        iterationsCount=5000, reprojectionError=5.0,\n",
    "        flags=cv2.SOLVEPNP_P3P)\n",
    "    #check for unique elements number\n",
    "    uniqueKps = undistKps[inliers]\n",
    "    uniqueDic = {}\n",
    "    for ui in uniqueKps:\n",
    "        if not ui[0][0] in uniqueDic:\n",
    "            uniqueDic[ui[0][0]] = ui\n",
    "   \n",
    "    if len(uniqueDic) <=10:\n",
    "        continue\n",
    "    if success and len(inliers) >=10 :\n",
    "        inliers = inliers[:, 0]\n",
    "        num_inliers = len(inliers)\n",
    "#         inlier_ratio = len(inliers) / len(undistKp)\n",
    "        success &= num_inliers >= 5\n",
    "\n",
    "        ret, R_vec, t = cv2.solvePnP(\n",
    "                imps[inliers], undistKps[inliers], K,\n",
    "                np.array([0., 0., 0., 0.]), rvec=R_vec, tvec=t,\n",
    "                useExtrinsicGuess=True, flags=cv2.SOLVEPNP_ITERATIVE)\n",
    "        assert ret\n",
    "\n",
    "        T_query_w = np.eye(4)\n",
    "        T_query_w[:3, :3] = cv2.Rodrigues(R_vec)[0]\n",
    "        T_query_w[:3, 3] = t[:, 0]\n",
    "        q = (R.from_dcm(T_query_w[:3,:3])).as_quat()\n",
    "        t = T_query_w[:3,3]\n",
    "        ## for iros workshop\n",
    "        T_w_query= np.linalg.inv(T_query_w)\n",
    "        q1 = (R.from_dcm(T_w_query[:3,:3])).as_quat()\n",
    "        t1 = T_w_query[:3,3]\n",
    "        \n",
    "\n",
    "        locResultStr.append(\"{} {:.6f} {:.6f} {:.6f} {:.6f} {:.6f} {:.6f} {:.6f} 1 {}\\n \\n\"\n",
    "                        .format(count,q[3],q[0],q[1],q[2],t[0],t[1],t[2],query_list[i]))\n",
    "        contestResultStr.append(\"{} {:.6f} {:.6f} {:.6f} {:.6f} {:.6f} {:.6f} {:.6f}\\n\"\n",
    "                        .format(query_list[i], q1[0],q1[1],q1[2],q1[3],t1[0],t1[1],t1[2]))\n",
    "        matches = allMatches[inliers]\n",
    "\n",
    "        if plotMatch == True:\n",
    "            for j in range(len(allMatches)):\n",
    "                if j in inliers:\n",
    "                    continue\n",
    "                else:\n",
    "                    allMatches[j][1] = -1  \n",
    "            for ii in range(len(globalKpNum)):\n",
    "\n",
    "                if ii==0:\n",
    "                    m = allMatches[:globalKpNum[ii][1]]\n",
    "                    m = m[m[:,1] >= 0]\n",
    "                    plot_matches(images_query[i], query['keypoints'],\n",
    "                     images_db[globalKpNum[ii][0]], db[globalKpNum[ii][0]]['keypoints'],\n",
    "                     m, color=(0, 1, 0), dpi=100,thickness=0.5,kp_size=6)\n",
    "                else:\n",
    "                    m = allMatches[globalKpNum[ii-1][1]:globalKpNum[ii][1]]\n",
    "                    m = m[m[:,1] >= 0]\n",
    "                    plot_matches(images_query[i], query['keypoints'],\n",
    "                     images_db[globalKpNum[ii][0]], db[globalKpNum[ii][0]]['keypoints'],\n",
    "                     m, color=(0, 1, 0), dpi=100,thickness=0.5,kp_size=6)\n",
    "                plt.savefig(result_path+str(count)+\"_matches\"+str(ii)+ \".jpg\")\n",
    "                plt.cla()\n",
    "                plt.close('all')\n",
    "                \n",
    "            allMatches=allMatches[inliers]\n",
    "            if len(nearest) > 1:\n",
    "                plot_images([images_query[i]], keypoints=[query['keypoints'][allMatches[:,0]]])\n",
    "                plt.savefig(result_path+str(count)+\"_matches.jpg\")\n",
    "                plt.cla()\n",
    "                plt.close('all')              \n",
    "            \n",
    "    count+=1\n",
    "    print(\"relocalization happend with:{} total reloc number:{}\".format(query_list[i],count))\n",
    "     \n",
    "          \n",
    "for l in locResultStr:\n",
    "    w.write(l)\n",
    "w.close()  \n",
    "\n",
    "for l in contestResultStr:\n",
    "    w1.write(l)\n",
    "w1.close() \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf_venv",
   "language": "python",
   "name": "hf_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
